{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bayes_opt import BayesianOptimization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from utils import MVTecDataset, MVTecActiveDataset, evaluate_accuracy, getFileList\n",
    "from models import MVTecCNN_BO\n",
    "\n",
    "import time\n",
    "import argparse\n",
    "import copy\n",
    "\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('-t', '--target', required=True, help='target class')\n",
    "parser.add_argument('-k', '--no_ensemble', default= 3, type=int, help='number of esemble models for active learning')\n",
    "parser.add_argument('--unlabel_ratio', default= 0.5, type=float, help='the ratio of unlabeled data')\n",
    "parser.add_argument('--sample_ratio', default= 0.1, type=float, help='the ratio of sampling from unlabeled pool')\n",
    "\n",
    "\n",
    "parser.add_argument('-c', '--no_cuda', required=False, default=None, help='which cuda')\n",
    "parser.add_argument('--lr', default= 0.001, type=float , required=False, help='learning rate')\n",
    "parser.add_argument('--no_epoch', default= 30, type= int, required=False, help='number of epochs')\n",
    "\n",
    "args = parser.parse_args(\"--target zipper -k 3 --unlabel_ratio 0.7 --sample_ratio 0.1 -c 3 --lr 0.001\".split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_class = args.target\n",
    "num_ensemble = args.no_ensemble\n",
    "sample_ratio =  args.sample_ratio\n",
    "unlabeled_ratio =  args.unlabel_ratio\n",
    "\n",
    "save_path = os.path.join('./saves_active/', target_class)\n",
    "\n",
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "activeBatchSize = 16\n",
    "best_accuracies = np.zeros(num_ensemble)\n",
    "best_models={}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if not os.path.exists(save_path):\n",
    "    os.makedirs(save_path)\n",
    "\n",
    "device_type='cuda'\n",
    "\n",
    "if args.no_cuda is not None:\n",
    "    device_type = 'cuda:'+str(args.no_cuda)\n",
    "    \n",
    "device = torch.device(device_type if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadActiveDataset(target_class):\n",
    "    normal_list_dir = [os.path.join('./data/', target_class, 'train', 'good'), os.path.join('./data/', target_class, 'test', 'good')]\n",
    "\n",
    "    test_dir = os.path.join('./data/', target_class, 'test')\n",
    "    test_subfolders = next(os.walk(test_dir))[1]\n",
    "\n",
    "    abnormal_list_dir=[]\n",
    "    \n",
    "    for item in test_subfolders:\n",
    "        if item != 'good':\n",
    "            abnormal_list_dir.append(os.path.join('./data/', target_class, 'test', item))\n",
    "    \n",
    "    normal_file_list, abnormal_file_list = getFileList(normal_list_dir, abnormal_list_dir)\n",
    "    normal_rand_idx = np.random.permutation(len(normal_file_list))\n",
    "    abnormal_rand_idx = np.random.permutation(len(abnormal_file_list))\n",
    "    \n",
    "    unlabeled_normal_num = int(unlabeled_ratio*len(normal_file_list))\n",
    "    unlabeled_abnormal_num = int(unlabeled_ratio*len(abnormal_file_list))\n",
    "    \n",
    "    unlabeled_normal_data_list = normal_file_list[normal_rand_idx[:unlabeled_normal_num]]\n",
    "    unlabeled_abnormal_data_list = abnormal_file_list[abnormal_rand_idx[:unlabeled_abnormal_num]]\n",
    "    \n",
    "    labeled_normal_data_list = normal_file_list[normal_rand_idx[unlabeled_normal_num:]]\n",
    "    labeled_abnormal_data_list = abnormal_file_list[abnormal_rand_idx[unlabeled_abnormal_num:]]\n",
    "    \n",
    "    return labeled_normal_data_list, labeled_abnormal_data_list, unlabeled_normal_data_list, unlabeled_abnormal_data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_normal_data_list, labeled_abnormal_data_list, unlabeled_normal_data_list, unlabeled_abnormal_data_list = loadActiveDataset(target_class)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_normal_data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset = MVTecActiveDataset(unlabeled_normal_data_list, unlabeled_abnormal_data_list, isUnlabeled=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_dataset = MVTecActiveDataset(labeled_normal_data_list, labeled_abnormal_data_list, isUnlabeled=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlabeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "154"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(labeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_num = int(len(labeled_dataset)*0.18)\n",
    "test_num = int(len(labeled_dataset)*0.2)\n",
    "total_train_num = len(labeled_dataset) - test_num\n",
    "\n",
    "train_num = total_train_num - val_num\n",
    "\n",
    "total_train_dataset, test_dataset =random_split(labeled_dataset,[total_train_num, test_num])\n",
    "\n",
    "train_dataset, valid_dataset = random_split(total_train_dataset,[train_num, val_num])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=8, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
    "\n",
    "active_loader = DataLoader(unlabeled_dataset, batch_size=activeBatchSize, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loaders = {0:train_loader, 1:valid_loader, 2:test_loader, 3:active_loader}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath_dataloader = os.path.join(save_path, f\"dataloader_target-{target_class}_ensemble-{num_ensemble}_unlabel-{unlabeled_ratio}_annotate-{sample_ratio}.pth\")\n",
    "torch.save(data_loaders, savepath_dataloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Esemble models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_esemble_models(best_val_acc, net):\n",
    "    if np.min(best_accuracies) < best_val_acc:\n",
    "        idx = np.argmin(best_accuracies)\n",
    "        best_models[idx] = net\n",
    "        best_accuracies[idx] = best_val_acc    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(lr, num_channel):        \n",
    "    net = MVTecCNN_BO(num_channel).to(device)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    best_val_acc = 0.    \n",
    "    num_epoch = 3\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        loss_count=0\n",
    "        loss_sum=0\n",
    "        for idx, (img, label) in enumerate(train_loader):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device, dtype=torch.float)\n",
    "            label = label.view(-1,1)\n",
    "            pred = net(img)\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(pred, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum+=loss.item()\n",
    "            loss_count+=1\n",
    "            if idx%10==0:\n",
    "                val_acc = evaluate_accuracy(net, valid_loader, device)\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc                    \n",
    "                best_model = copy.deepcopy(net)\n",
    "        scheduler.step()\n",
    "        \n",
    "    save_esemble_models(best_val_acc, best_model.eval())\n",
    "    return best_val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cnn_function(lr, num_channel):\n",
    "    num_channel = int(8 + num_channel*54)   # min 8, max 64\n",
    "    best_val_accuracy = train(lr, num_channel)    \n",
    "    return best_val_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounded region of parameter space\n",
    "pbounds = {'lr': (1e-3, 0.1), 'num_channel':(0, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=cnn_function,\n",
    "    pbounds=pbounds,\n",
    "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     | num_ch... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.6074  \u001b[0m | \u001b[0m 0.04229 \u001b[0m | \u001b[0m 0.7203  \u001b[0m |\n",
      "| \u001b[95m 2       \u001b[0m | \u001b[95m 0.6222  \u001b[0m | \u001b[95m 0.001011\u001b[0m | \u001b[95m 0.3023  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.6     \u001b[0m | \u001b[0m 0.01553 \u001b[0m | \u001b[0m 0.09234 \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.5926  \u001b[0m | \u001b[0m 0.01177 \u001b[0m | \u001b[0m 0.3689  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.5926  \u001b[0m | \u001b[0m 0.08317 \u001b[0m | \u001b[0m 0.6601  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.5926  \u001b[0m | \u001b[0m 0.01578 \u001b[0m | \u001b[0m 0.6288  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.6074  \u001b[0m | \u001b[0m 0.009521\u001b[0m | \u001b[0m 0.7587  \u001b[0m |\n",
      "| \u001b[0m 8       \u001b[0m | \u001b[0m 0.6     \u001b[0m | \u001b[0m 0.04239 \u001b[0m | \u001b[0m 0.7204  \u001b[0m |\n",
      "=================================================\n",
      "Time consumed:  249.4896755218506\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "optimizer.maximize(\n",
    "    init_points=3,\n",
    "    n_iter=5\n",
    ")\n",
    "end = time.time()\n",
    "print('Time consumed: ' , end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.6222222222222222,\n",
       " 'params': {'lr': 0.0010113231069171437, 'num_channel': 0.30233257263183977}}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "int(8 + 0.29725476914104565*54)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- original CNN accuracy 0.7674 (lr: 0.001, num_channel: 32)\n",
    "- auto-hyperparameter tuning with BO 0.8139 (lr: 0.00116, num_channel: 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.60740741, 0.62222222, 0.60740741])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath_ensembles = os.path.join(save_path, f\"ensemble_models_target-{target_class}_ensemble-{num_ensemble}_unlabel-{unlabeled_ratio}_annotate-{sample_ratio}.pth\")\n",
    "torch.save(best_models, savepath_ensembles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save & Load state dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath_dataloader = os.path.join(save_path, f\"dataloader_target-{target_class}_ensemble-{num_ensemble}_unlabel-{unlabeled_ratio}_annotate-{sample_ratio}.pth\")\n",
    "data_loaders = torch.load(savepath_dataloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = data_loaders[0]\n",
    "valid_loader =  data_loaders[1]\n",
    "test_loader =  data_loaders[2]\n",
    "active_loader =  data_loaders[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "273"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(unlabeled_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "unlabeled_dataset = active_loader.dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "savepath_ensembles = os.path.join(save_path, f\"ensemble_models_target-{target_class}_ensemble-{num_ensemble}_unlabel-{unlabeled_ratio}_annotate-{sample_ratio}.pth\")\n",
    "best_models = torch.load(savepath_ensembles)\n",
    "\n",
    "best_models_cpu={}\n",
    "for i in best_models:\n",
    "    best_models_cpu[i] = best_models[i].cpu()\n",
    "\n",
    "torch.save(best_models_cpu, savepath_ensembles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MVTecCNN_BO(\n",
       "  (conv1): Conv2d(3, 48, kernel_size=(5, 5), stride=(2, 2))\n",
       "  (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv2): Conv2d(48, 96, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv3): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (conv4): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1))\n",
       "  (bn4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (relu): ReLU()\n",
       "  (fc1): Linear(in_features=9600, out_features=128, bias=True)\n",
       "  (bn_fc1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "  (sigmoid): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models[2].cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models = torch.load(savepath_ensembles)\n",
    "best_model_num_channels=[]\n",
    "best_accuracies =[]\n",
    "for i in range(num_ensemble):\n",
    "    best_model_num_channels.append(best_models_cpu[i].num_channel)    \n",
    "    best_accuracies.append(evaluate_accuracy(best_models_cpu[i].eval(), valid_loader, device='cpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5925925925925926, 0.4074074074074074, 0.4074074074074074]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_model = best_models[np.argmax(best_accuracies)].cpu().eval()\n",
    "original_model_test_acc = evaluate_accuracy(original_model, test_loader, device='cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.43333333333333335\n"
     ]
    }
   ],
   "source": [
    "print(original_model_test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_models_cpu={}\n",
    "for i in best_models:\n",
    "    best_models_cpu[i] = best_models[i].eval().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: MVTecCNN_BO(\n",
       "   (conv1): Conv2d(3, 46, kernel_size=(5, 5), stride=(2, 2))\n",
       "   (bn1): BatchNorm2d(46, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(46, 92, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (bn2): BatchNorm2d(92, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(92, 184, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (bn3): BatchNorm2d(184, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(184, 368, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (bn4): BatchNorm2d(368, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (relu): ReLU()\n",
       "   (fc1): Linear(in_features=9200, out_features=128, bias=True)\n",
       "   (bn_fc1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "   (sigmoid): Sigmoid()\n",
       " ),\n",
       " 1: MVTecCNN_BO(\n",
       "   (conv1): Conv2d(3, 24, kernel_size=(5, 5), stride=(2, 2))\n",
       "   (bn1): BatchNorm2d(24, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(24, 48, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (bn2): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(48, 96, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (bn3): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(96, 192, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (bn4): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (relu): ReLU()\n",
       "   (fc1): Linear(in_features=4800, out_features=128, bias=True)\n",
       "   (bn_fc1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "   (sigmoid): Sigmoid()\n",
       " ),\n",
       " 2: MVTecCNN_BO(\n",
       "   (conv1): Conv2d(3, 48, kernel_size=(5, 5), stride=(2, 2))\n",
       "   (bn1): BatchNorm2d(48, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv2): Conv2d(48, 96, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (bn2): BatchNorm2d(96, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv3): Conv2d(96, 192, kernel_size=(5, 5), stride=(1, 1))\n",
       "   (bn3): BatchNorm2d(192, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (conv4): Conv2d(192, 384, kernel_size=(3, 3), stride=(1, 1))\n",
       "   (bn4): BatchNorm2d(384, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   (relu): ReLU()\n",
       "   (fc1): Linear(in_features=9600, out_features=128, bias=True)\n",
       "   (bn_fc1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "   (fc2): Linear(in_features=128, out_features=1, bias=True)\n",
       "   (sigmoid): Sigmoid()\n",
       " )}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_models_cpu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add annotation from unlabeled data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentDataset(total_train_dataset, labeled_dataset, unlabeled_dataset, idx):\n",
    "    \n",
    "    original_idx = total_train_dataset.indices\n",
    "    original_data_list = np.array(labeled_dataset.data_list)[original_idx]\n",
    "    original_label_list = np.array(labeled_dataset.label_list)[original_idx]\n",
    "    \n",
    "    active_data_list = np.array(unlabeled_dataset.data_list)[idx]    \n",
    "    active_label_list = np.array(unlabeled_dataset.label_list)[idx]\n",
    "    \n",
    "    labeled_dataset.data_list = original_data_list.tolist() + active_data_list.tolist()\n",
    "    labeled_dataset.label_list = original_label_list.tolist() + active_label_list.tolist()\n",
    "\n",
    "    \n",
    "    val_num = int(len(labeled_dataset)*0.20)\n",
    "    train_num = len(labeled_dataset)  - val_num\n",
    "\n",
    "    new_train_dataset, new_valid_dataset =random_split(labeled_dataset,[train_num, val_num])\n",
    "\n",
    "    new_train_loader = DataLoader(new_train_dataset, batch_size=8, shuffle=True, drop_last=True)\n",
    "    new_valid_loader = DataLoader(new_valid_dataset, batch_size=8, shuffle=False)\n",
    "    \n",
    "    return new_train_loader, new_valid_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, (img, label) in enumerate(active_loader):\n",
    "#     img = img.to(device)\n",
    "#     label = label.to(device, dtype=torch.float)\n",
    "       \n",
    "    for model_idx in best_models:\n",
    "\n",
    "        best_models[model_idx]\n",
    "        label = label.view(-1,1)\n",
    "        if model_idx==0:\n",
    "            total_tensor = best_models[model_idx](img)\n",
    "        else:\n",
    "            total_tensor = torch.cat((total_tensor, best_models[model_idx](img)), dim=1)        \n",
    "    \n",
    "    p = torch.mean(total_tensor, dim=1)\n",
    "    H = -p*torch.log(p)\n",
    "    \n",
    "    if idx==0:\n",
    "        total_H = H\n",
    "    else:\n",
    "        total_H = torch.cat((total_H, H))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([273])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_H.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "27\n"
     ]
    }
   ],
   "source": [
    "query_num = int(len(unlabeled_dataset)*sample_ratio)\n",
    "print(query_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_vals, active_idx = torch.topk(total_H, query_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 14,  70,   2,  60, 261, 135,  28,  61, 106, 122,  48, 117,  76,  15,\n",
       "        166, 217,  19,  43,  49, 171, 127,  52,  23,  56, 179,  35,  82])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_idx.cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "active_train_loader, active_valid_loader = augmentDataset(total_train_dataset, copy.deepcopy(labeled_dataset), unlabeled_dataset, active_idx.cpu())\n",
    "\n",
    "rand_idx = np.random.permutation(len(unlabeled_dataset))[:query_num]\n",
    "normal_train_loader, normal_valid_loader = augmentDataset(total_train_dataset, copy.deepcopy(labeled_dataset), unlabeled_dataset, rand_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def activeTrain(idx, lr, isActiveLearn):\n",
    "    \n",
    "    if isActiveLearn:\n",
    "        method='active'\n",
    "        train_loader = active_train_loader\n",
    "        valid_loader = active_valid_loader\n",
    "    else:\n",
    "        method='normal'\n",
    "        train_loader = normal_train_loader\n",
    "        valid_loader = normal_valid_loader\n",
    "    \n",
    "    net = copy.deepcopy(best_models[idx])\n",
    "    net.to(device).train()\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = torch.optim.Adam(net.parameters(), lr=lr)\n",
    "    best_val_acc = 0.\n",
    "    \n",
    "    num_epoch = 20\n",
    "    \n",
    "    scheduler = StepLR(optimizer, step_size=5, gamma=0.5)\n",
    "    \n",
    "    for epoch in range(num_epoch):\n",
    "        loss_count=0\n",
    "        loss_sum=0\n",
    "        for idx, (img, label) in enumerate(train_loader):\n",
    "            img = img.to(device)\n",
    "            label = label.to(device, dtype=torch.float)\n",
    "            label = label.view(-1,1)\n",
    "            pred = net(img)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss = criterion(pred, label)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            loss_sum+=loss.item()\n",
    "            loss_count+=1\n",
    "            if idx%10==0:\n",
    "                net.eval()\n",
    "                val_acc = evaluate_accuracy(net, valid_loader, device)\n",
    "                if val_acc > best_val_acc:\n",
    "                    best_val_acc = val_acc\n",
    "                    best_model = copy.deepcopy(net)\n",
    "\n",
    "                net.train()\n",
    "        scheduler.step()   \n",
    "#     save_esemble_models(best_val_acc, net.eval())\n",
    "    return best_val_acc, best_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_best_active_acc = 0\n",
    "savepath_active = os.path.join(save_path, f\"active_target-{target_class}_ensemble-{num_ensemble}_unlabel-{unlabeled_ratio}_annotate-{sample_ratio}.pth\")\n",
    "\n",
    "def cnn_active_function(lr, model_index):    \n",
    "    global global_best_active_acc\n",
    "    if model_index==1:\n",
    "        idx=num_ensemble-1\n",
    "    else:\n",
    "        idx = int(model_index*num_ensemble)      \n",
    "    best_acc, best_model = activeTrain(idx, lr, isActiveLearn=True)\n",
    "    \n",
    "    if best_acc > global_best_active_acc:\n",
    "        global_best_active_acc = best_acc\n",
    "        torch.save(best_model.state_dict(), savepath_active)\n",
    "    \n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounded region of parameter space\n",
    "active_pbounds = {'lr': (1e-5, 0.01), 'model_index':(0, 1)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=cnn_active_function,\n",
    "    pbounds=active_pbounds,\n",
    "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     | model_... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.9133  \u001b[0m | \u001b[0m 0.004176\u001b[0m | \u001b[0m 0.7203  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.6067  \u001b[0m | \u001b[0m 1.114e-0\u001b[0m | \u001b[0m 0.3023  \u001b[0m |\n",
      "| \u001b[0m 3       \u001b[0m | \u001b[0m 0.9067  \u001b[0m | \u001b[0m 0.001097\u001b[0m | \u001b[0m 0.3689  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.8867  \u001b[0m | \u001b[0m 0.008302\u001b[0m | \u001b[0m 0.6601  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.9     \u001b[0m | \u001b[0m 0.00425 \u001b[0m | \u001b[0m 0.7205  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8667  \u001b[0m | \u001b[0m 0.003422\u001b[0m | \u001b[0m 0.7179  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8733  \u001b[0m | \u001b[0m 0.001595\u001b[0m | \u001b[0m 0.7197  \u001b[0m |\n",
      "=================================================\n",
      "Time consumed:  1661.099769115448\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=5,   \n",
    ")\n",
    "end = time.time()\n",
    "print('Time consumed: ' , end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'target': 0.9133333333333333,\n",
       " 'params': {'lr': 0.004176049826978714, 'model_index': 0.7203244934421581}}"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "optimizer.max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_idx = int(optimizer.max['params']['model_index']*num_ensemble)\n",
    "if model_idx == num_ensemble:\n",
    "    model_idx = num_ensemble-1\n",
    "\n",
    "active_final_model = MVTecCNN_BO(best_model_num_channels[model_idx]).to(device)\n",
    "active_final_model.load_state_dict(torch.load(savepath_active, map_location=device))\n",
    "\n",
    "active_model_test_acc = evaluate_accuracy(active_final_model.eval(), test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_best_normal_acc = 0\n",
    "savepath_normal = os.path.join(save_path, f\"normal_target-{target_class}_ensemble-{num_ensemble}_unlabel-{unlabeled_ratio}_annotate-{sample_ratio}.pth\")\n",
    "\n",
    "def cnn_normal_function(lr, model_index):\n",
    "    global global_best_normal_acc\n",
    "    if model_index==1:\n",
    "        idx=num_ensemble-1\n",
    "    else:\n",
    "        idx = int(model_index*num_ensemble)      \n",
    "    best_acc, best_model = activeTrain(idx, lr, isActiveLearn=False)\n",
    "    \n",
    "    if best_acc > global_best_normal_acc:\n",
    "        global_best_normal_acc = best_acc\n",
    "        torch.save(best_model.state_dict(), savepath_normal)\n",
    "    return best_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = BayesianOptimization(\n",
    "    f=cnn_normal_function,\n",
    "    pbounds=active_pbounds,\n",
    "    verbose=2, # verbose = 1 prints only when a maximum is observed, verbose = 0 is silent\n",
    "    random_state=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   |    lr     | model_... |\n",
      "-------------------------------------------------\n",
      "| \u001b[0m 1       \u001b[0m | \u001b[0m 0.8733  \u001b[0m | \u001b[0m 0.004176\u001b[0m | \u001b[0m 0.7203  \u001b[0m |\n",
      "| \u001b[0m 2       \u001b[0m | \u001b[0m 0.58    \u001b[0m | \u001b[0m 1.114e-0\u001b[0m | \u001b[0m 0.3023  \u001b[0m |\n",
      "| \u001b[95m 3       \u001b[0m | \u001b[95m 0.8933  \u001b[0m | \u001b[95m 0.001097\u001b[0m | \u001b[95m 0.3689  \u001b[0m |\n",
      "| \u001b[0m 4       \u001b[0m | \u001b[0m 0.86    \u001b[0m | \u001b[0m 0.008302\u001b[0m | \u001b[0m 0.6601  \u001b[0m |\n",
      "| \u001b[0m 5       \u001b[0m | \u001b[0m 0.86    \u001b[0m | \u001b[0m 0.00425 \u001b[0m | \u001b[0m 0.7205  \u001b[0m |\n",
      "| \u001b[0m 6       \u001b[0m | \u001b[0m 0.8467  \u001b[0m | \u001b[0m 0.003422\u001b[0m | \u001b[0m 0.7179  \u001b[0m |\n",
      "| \u001b[0m 7       \u001b[0m | \u001b[0m 0.8667  \u001b[0m | \u001b[0m 0.001595\u001b[0m | \u001b[0m 0.7197  \u001b[0m |\n",
      "=================================================\n",
      "Time consumed:  1654.0690655708313\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "optimizer.maximize(\n",
    "    init_points=2,\n",
    "    n_iter=5, \n",
    ")\n",
    "end = time.time()\n",
    "print('Time consumed: ' , end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_idx = int(optimizer.max['params']['model_index']*num_ensemble)\n",
    "if model_idx == num_ensemble:\n",
    "    model_idx = num_ensemble-1\n",
    "\n",
    "normal_final_model = MVTecCNN_BO(best_model_num_channels[model_idx]).to(device)\n",
    "normal_final_model.load_state_dict(torch.load(savepath_normal, map_location=device))\n",
    "\n",
    "normal_model_test_acc = evaluate_accuracy(normal_final_model.eval(), test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original_model_test_acc: 0.43333333333333335 \t active_model_test_acc:0.78 \t normal_model_test_acc:0.6333333333333333\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'original_model_test_acc: {original_model_test_acc} \\t active_model_test_acc:{active_model_test_acc} \\\n",
    "\\t normal_model_test_acc:{normal_model_test_acc}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
